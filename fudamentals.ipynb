{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d697aec2-fa6d-4a2c-afbc-88b064985b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a24a96-3cf9-47b4-ada2-6079ae4bf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ====================================================\n",
    "### Fundamentals of Vector Databases\n",
    "### ====================================================\n",
    "\n",
    "### ====================================================\n",
    "### 1. Embeddings:\n",
    "###    Definition and purpose:\n",
    "###    Transform raw data (words) into numerical vectors.\n",
    "### ====================================================\n",
    "\n",
    "### Load spaCy's medium English model which provides 300-d word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2bf35a9-9f00-4c87-91a1-7dd8dc4f5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy's medium English model which provides 300-d word vectors.\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c3ab31-be6d-4fad-8143-b96649062cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sample set of words.\n",
    "words = [\"apple\", \"banana\", \"cat\", \"dog\", \"computer\", \"python\", \"data\", \"science\", \"machine\", \"learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192f2398-52b3-4dcd-bc02-d8f24adb4ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Embeddings for Sample Words ===\n",
      "apple: [-0.6334   0.18981 -0.53544 -0.52658 -0.30001] ...\n",
      "banana: [-0.6334   0.18981 -0.53544 -0.52658 -0.30001] ...\n",
      "cat: [-0.72483   0.42538   0.025489 -0.39807   0.037463] ...\n",
      "dog: [-0.72483   0.42538   0.025489 -0.39807   0.037463] ...\n",
      "computer: [-0.65942   0.048198  0.3459   -0.57023   0.090037] ...\n",
      "python: [-0.6037    -0.31122    0.29572   -0.0011134  0.31605  ] ...\n",
      "data: [-0.60261  0.11757  0.2091   0.16977 -0.2427 ] ...\n",
      "science: [-0.79222   0.69891  -0.033084  0.1249   -0.038876] ...\n",
      "machine: [-0.72883    0.20718   -0.0033379 -0.0027673 -0.17204  ] ...\n",
      "learning: [-0.9261   0.36204 -0.15093 -0.37449 -0.42103] ...\n"
     ]
    }
   ],
   "source": [
    "#Obtain embeddings for these words.\n",
    "embeddings = np.array([nlp(word).vector for word in words]).astype(\"float32\")\n",
    "print(\"=== Embeddings for Sample Words ===\")\n",
    "for word, vec in zip(words, embeddings):\n",
    "    # Display the first five dimensions for brevity.\n",
    "    print(f\"{word}: {vec[:5]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c8d0ad1-a287-4c74-828c-9e438dcee419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# 2. Similarity Search:\n",
    "#    - Key metrics: cosine similarity, Euclidean (L2) distance.\n",
    "#    - How similarity measures help in finding “close” vectors.\n",
    "# ===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0289d8-241e-470f-83f1-b72df2ff74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two words to compare.\n",
    "word1 = \"apple\"\n",
    "word2 = \"banana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b2f616-4164-4fe9-8561-f927cf38b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = nlp(word1).vector.reshape(1, -1)\n",
    "vec2 = nlp(word2).vector.reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7a3ef4-b4f2-4e94-8eb9-e7c285dc23c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity.\n",
    "cos_sim = cosine_similarity(vec1, vec2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46564832-2345-4c96-b83f-a2a5fb774277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Euclidean (L2) distance.\n",
    "euclidean = np.linalg.norm(vec1 - vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4c0023-9057-4cb5-85e4-e564e8ac4770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Similarity Search ===\n",
      "Similarity between 'apple' and 'banana':\n",
      "Cosine Similarity: 1.0000\n",
      "Euclidean Distance: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Similarity Search ===\")\n",
    "print(f\"Similarity between '{word1}' and '{word2}':\")\n",
    "print(f\"Cosine Similarity: {cos_sim:.4f}\")\n",
    "print(f\"Euclidean Distance: {euclidean:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8cf05f2-56c4-4839-ab3d-b1652adb1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# 3. Indexing Techniques:\n",
    "#    Overview of indexing methods (FAISS, Annoy, HNSW).\n",
    "#    Benefits of approximate nearest neighbor (ANN) searches.\n",
    "# ===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ecea40f-b67b-420f-9edd-672d9c791c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use FAISS for this demonstration.\n",
    "# Get the dimensionality of our embeddings.\n",
    "d = embeddings.shape[1]  # should be 300 for spaCy's en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f5161bf-878e-47de-ba1e-2e31c2de904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FAISS Index ===\n",
      "FAISS index created with sample embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Create a FAISS index using L2 (Euclidean) distance.\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings)\n",
    "print(\"=== FAISS Index ===\")\n",
    "print(\"FAISS index created with sample embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb955f02-d6d5-4342-bbdf-6a80d4a31aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a query: find the top 3 nearest neighbors to \"computer\".\n",
    "query_word = \"computer\"\n",
    "query_vec = nlp(query_word).vector.reshape(1, -1)\n",
    "k = 3  # number of nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a19c8e6-5626-473d-83d2-eb0313b61566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nearest neighbors for 'computer':\n",
      "1. computer (Distance: 0.0000)\n",
      "2. machine (Distance: 41.2062)\n",
      "3. learning (Distance: 50.7203)\n"
     ]
    }
   ],
   "source": [
    "distances, indices = index.search(query_vec, k)\n",
    "print(f\"\\nNearest neighbors for '{query_word}':\")\n",
    "for rank, idx in enumerate(indices[0]):\n",
    "    print(f\"{rank + 1}. {words[idx]} (Distance: {distances[0][rank]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f883f-5eea-4d65-8736-530b9b647768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# 4. Popular Tools & Comparison:\n",
    "#    - Popular Tools: FAISS, Pinecone, Milvus, Qdrant.\n",
    "#    - Differences between vector databases and traditional relational databases.\n",
    "# ====================================================\n",
    "#\n",
    "# Popular Tools:\n",
    "#   • FAISS: An efficient similarity search library developed by Facebook.\n",
    "#   • Pinecone: A fully managed vector database service.\n",
    "#   • Milvus: An open-source vector database optimized for scalable similarity search.\n",
    "#   • Qdrant: A high-performance vector database designed for integration and ease-of-use.\n",
    "#\n",
    "# Differences:\n",
    "#   • Vector databases are specialized to store and search high-dimensional vectors,\n",
    "#     making them ideal for similarity search in unstructured data (e.g., images, text).\n",
    "#   • Traditional relational databases excel in structured, tabular data with exact match queries.\n",
    "#\n",
    "# These comments serve as a conceptual overview. You can expand upon these points during your lecture.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
